{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAD Score Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Sophie Sigfstead\n",
    "\n",
    "Purpose of the notebook: Currently I am working to design a better thresholding mechanism for our SNP activity difference scores. One method proposed is to use FDR to include / disclude SNPs based on whether or not we reject the null hypothesis of SAD_<track_i>_<snp_j> = 0. \n",
    "\n",
    "In order to do these computations (e.g z-test etc.) I'd like to first see how the SAD scores are distributed on average across tracks. As such, I'm doing some simple visualizations here to see what this looks like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       SAD0      SAD1      SAD2      SAD3      SAD4      SAD5      SAD6  \\\n",
      "0  0.000029  0.000004 -0.000087 -0.000120 -0.000009  0.000006  0.000010   \n",
      "1  0.000142 -0.000034 -0.000021  0.000067  0.000462  0.000327  0.000635   \n",
      "2 -0.000003  0.000141  0.000202  0.000088  0.000104  0.000171  0.000078   \n",
      "3  0.000049  0.000041  0.000054  0.000051  0.000037  0.000045  0.000041   \n",
      "4  0.000023  0.000017  0.000014  0.000039  0.000024  0.000031  0.000016   \n",
      "\n",
      "       SAD7      SAD8      SAD9  ...    SAD674    SAD675    SAD676    SAD677  \\\n",
      "0 -0.000017 -0.000023 -0.000057  ... -0.002296  0.002531 -0.000041  0.002285   \n",
      "1  0.000135  0.000390 -0.000043  ...  0.002403  0.002401  0.000389  0.001868   \n",
      "2  0.000091  0.000102  0.000137  ...  0.000347 -0.000556  0.001503 -0.000402   \n",
      "3  0.000027  0.000044  0.000039  ...  0.000195  0.000122  0.000713 -0.000057   \n",
      "4  0.000019  0.000024  0.000011  ...  0.000821  0.001335  0.000609  0.001102   \n",
      "\n",
      "     SAD678    SAD679    SAD680    SAD681    SAD682    SAD683  \n",
      "0  0.001995  0.003384  0.005993  0.005417  0.000397  0.002329  \n",
      "1  0.001102  0.001403  0.000915  0.000861  0.001096  0.001533  \n",
      "2 -0.000185 -0.000668 -0.001478 -0.001198 -0.000024 -0.000535  \n",
      "3  0.000006  0.000132 -0.000150 -0.000220 -0.000121  0.000315  \n",
      "4  0.000834  0.001256  0.001814  0.001707  0.000769  0.001490  \n",
      "\n",
      "[5 rows x 684 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the directory containing the CSV files\n",
    "csv_directory = \"../GWAS_Data/1000genomes_as_csv\"\n",
    "\n",
    "# Create an empty DataFrame to hold the combined SAD values\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "# Define the maximum number of rows\n",
    "max_rows = 5_000_000\n",
    "\n",
    "# Loop through all CSV files in the directory\n",
    "for file_name in (os.listdir(csv_directory)):\n",
    "    if file_name.endswith(\".csv\"):  # Ensure the file is a CSV\n",
    "        file_path = os.path.join(csv_directory, file_name)\n",
    "        \n",
    "        # Read the CSV file in chunks to handle large file sizes\n",
    "        chunk_size = 10**6  # Adjust chunk size as needed\n",
    "        for chunk in pd.read_csv(file_path, chunksize=chunk_size):\n",
    "            # Extract all columns starting with \"SAD\"\n",
    "            sad_columns = [col for col in chunk.columns if col.startswith(\"SAD\")]\n",
    "            sad_chunk = chunk[sad_columns]\n",
    "            \n",
    "            # Append the SAD columns to the combined DataFrame\n",
    "            combined_df = pd.concat([combined_df, sad_chunk], ignore_index=True)\n",
    "            # Break the outer loop if the maximum row limit is reached\n",
    "            if len(combined_df) >= max_rows:\n",
    "                break\n",
    "            \n",
    "    # Break the outer loop if the maximum row limit is reached\n",
    "    if len(combined_df) >= max_rows:\n",
    "        break    # Break the outer loop if the maximum row limit is reached\n",
    "       \n",
    "\n",
    "# Save the combined DataFrame to a CSV file\n",
    "combined_df.to_csv(\"combined_sad_values.csv\", index=False)\n",
    "\n",
    "# Display the first few rows of the combined DataFrame\n",
    "print(combined_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming `df` contains the data with columns SAD0, SAD1, ..., SAD683\n",
    "columns_to_plot = [col for col in combined_df.columns if col.startswith(\"SAD\")]\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot each column as a KDE (Kernel Density Estimate) plot\n",
    "for column in columns_to_plot:\n",
    "    sns.kdeplot(combined_df[column], label=column, linewidth=1)\n",
    "\n",
    "# Add labels and legend\n",
    "plt.title(\"Bell Curves for Each Dataset (SAD Columns)\", fontsize=16)\n",
    "plt.xlabel(\"Value\", fontsize=14)\n",
    "plt.ylabel(\"Density\", fontsize=14)\n",
    "plt.legend(loc='upper right', fontsize=10, ncol=2)  # Adjust legend placement and size\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
