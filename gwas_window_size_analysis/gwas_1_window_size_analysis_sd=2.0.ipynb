{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GWAS 1: Window Size Analysis - SD = 2.0\n",
    "Author: Sophie Sigfstead \n",
    "\n",
    "Purpose: This is a copy of the gwas_1_window_size_analysis_sd=1.0.ipynb, now with SD = 2.0. \n",
    "\n",
    "This is an in-depth analysis of loci size and how it affects the results of our method for GWAS 1 (Depression).\n",
    "Specifically, my goal was to test various window sizes and see how this affected the accuracy of both our method (i.e., using the brain track set) versus a random set.\n",
    "\n",
    "When I refer to window size, this is the distance around a significant snp that is eliminated in the GWAS 1 procedure. SNPs are selected by order of p-value, with any snps with base pair locations within the window size (to the left or right) being eliminated (on the basis that there would be LD etc.). This repeats until there are no SNPs remaining that meet the p-value threshold. In Dr. Cai's original study, she used +/- 1Mb as the window size, and we have replicated this procedure. However, this creates very large windows and potentially doesn't differentiate our method as well (to be seen in this notebook).\n",
    "\n",
    "In the gwas_1_single_track_analysis directory, I performed multiple analyses comparing the results of our method using brain track sets versus random sets, using a 1Mb window size. Suprisingly, while the brain tracks were a bit better, they weren't as improved as we'd expect. On closer inspection, within the matching loci, the distance between our identified SNP and the study's identified SNP was at most 500kB, while the same was not necessarily true for the random tracks. As such, it may be that the 1Mb window is too large to differentiate our method - or, it could be that tissue specificity is not as important as we assumed.\n",
    "\n",
    "In this notebook, I will provide the results of running our method with various window sizes (250kb, 375kb, 500kb, 750kb, 1Mb), comparing the brain track set (\"reference\") to the aggregated result of 16 random sets (id = a through p). The random sets contain tracks that are not brain tracks, and were sampled without replacement, so that the sets contain an diverse representation of all the tracks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "window_sizes = [250000, 375000, 500000, 750000, 1000000]\n",
    "\n",
    "keys = ['a', 'b', 'c', 'd', 'e', 'f','g','h','i','j','k','l','m','n','o','p']\n",
    "\n",
    "coding_snps_file =  pd.read_csv('../gwas_1_single_track_analysis/coding_region_set.csv')\n",
    "coding_snps_set = set(coding_snps_file['snp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>window</th>\n",
       "      <th>total_snps</th>\n",
       "      <th>total_coding</th>\n",
       "      <th>total_non_coding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000000</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>750000</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500000</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>375000</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250000</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    window total_snps total_coding total_non_coding\n",
       "4  1000000         29            0               29\n",
       "3   750000         31            0               31\n",
       "2   500000         37            1               36\n",
       "1   375000         37            0               37\n",
       "0   250000         44            0               44"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_results = pd.DataFrame(columns = ['window', 'total_snps', 'total_coding', 'total_non_coding'])\n",
    "# Create a reference table\n",
    "for window in window_sizes: \n",
    "    reference_directory = f\"snp_lists_results/id=reference/window={window}/filtered_snps_gwas_1_sd=0.0.csv\"\n",
    "    reference_snps = pd.read_csv(reference_directory)\n",
    "    reference_coding_snps= len(reference_snps[reference_snps['snp'].isin(coding_snps_set)])\n",
    "    reference_results = reference_results._append({'window': window, 'total_snps': len(reference_snps), \n",
    "                        'total_coding':reference_coding_snps, 'total_non_coding': (len(reference_snps)-reference_coding_snps)}, ignore_index=True)\n",
    "    \n",
    "reference_results.sort_values(by=['window'], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above table simply outlines the reference set sizes for each window size. For example, for window size 250000, the reference set contains 44 total snps, 0 of which are coding.\n",
    "Below, I will create a table for each window size. Note that all of the results are done using a 2.0 SD threshold in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to create a table for each window size\n",
    "def create_window_size_results(window):\n",
    "    # Initialize the main DataFrame\n",
    "    df = pd.DataFrame(columns=[\"set\", \"total_snps_found\", \"total_snps_overlap\", \"total_loci_overlap\", \"total_coding_snps\", \"average_p_value\"])\n",
    "\n",
    "    # Create the reference result\n",
    "    reference_data = pd.read_csv(f\"combined_results/id=reference/window={window}/combined_result_sd=2.0.csv\").iloc[0]\n",
    "    reference_dict = {\n",
    "        \"set\": \"reference\",\n",
    "        \"total_snps_found\": reference_data['num_snps_found'],\n",
    "        \"total_snps_overlap\": reference_data['num_snps_overlap'],\n",
    "        \"total_loci_overlap\": reference_data['num_loci_overlap'],\n",
    "        \"total_coding_snps\": reference_data['num_coding_snps'],\n",
    "        \"average_p_value\": reference_data['p_value']\n",
    "    }\n",
    "    df = pd.concat([df, pd.DataFrame([reference_dict])], ignore_index=True)\n",
    "\n",
    "    # Initialize a DataFrame to collect all random set data\n",
    "    id_data = pd.DataFrame(columns=[\"set\", \"total_snps_found\", \"total_snps_overlap\", \"total_loci_overlap\", \"total_coding_snps\", \"average_p_value\"])\n",
    "    keys = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p']\n",
    "\n",
    "    # Collect data for each random set (a - p)\n",
    "    for key in keys:\n",
    "        id_data_path = f\"combined_results/id={key}/window={window}/combined_result_sd=2.0.csv\"\n",
    "        id_data_df = pd.read_csv(id_data_path).iloc[0]\n",
    "        id_data_dict = {\n",
    "            \"set\": key,\n",
    "            \"total_snps_found\": id_data_df['num_snps_found'],\n",
    "            \"total_snps_overlap\": id_data_df['num_snps_overlap'],\n",
    "            \"total_loci_overlap\": id_data_df['num_loci_overlap'],\n",
    "            \"total_coding_snps\": id_data_df['num_coding_snps'],\n",
    "            \"average_p_value\": id_data_df['p_value']\n",
    "        }\n",
    "        id_data = pd.concat([id_data, pd.DataFrame([id_data_dict])], ignore_index=True)\n",
    "\n",
    "    # Aggregate the statistics across all random sets\n",
    "    agg_id_data_mean = {\n",
    "        \"set\": \"random_aggregated_mean\",\n",
    "        \"total_snps_found\": id_data['total_snps_found'].mean(),\n",
    "        \"total_snps_overlap\": id_data['total_snps_overlap'].mean(),\n",
    "        \"total_loci_overlap\": id_data['total_loci_overlap'].mean(),\n",
    "        \"total_coding_snps\": id_data['total_coding_snps'].mean(),\n",
    "        \"average_p_value\": id_data['average_p_value'].mean()\n",
    "    }\n",
    "    agg_id_data_median = {\n",
    "        \"set\": \"random_aggregated_median\",\n",
    "        \"total_snps_found\": id_data['total_snps_found'].median(),\n",
    "        \"total_snps_overlap\": id_data['total_snps_overlap'].median(),\n",
    "        \"total_loci_overlap\": id_data['total_loci_overlap'].median(),\n",
    "        \"total_coding_snps\": id_data['total_coding_snps'].median(),\n",
    "        \"average_p_value\": id_data['average_p_value'].median()\n",
    "    }\n",
    "    agg_id_data_max = {\n",
    "        \"set\": \"random_aggregated_max\",\n",
    "        \"total_snps_found\": id_data['total_snps_found'].max(),\n",
    "        \"total_snps_overlap\": id_data['total_snps_overlap'].max(),\n",
    "        \"total_loci_overlap\": id_data['total_loci_overlap'].max(),\n",
    "        \"total_coding_snps\": id_data['total_coding_snps'].max(),\n",
    "        \"average_p_value\": id_data['average_p_value'].max()\n",
    "    }\n",
    "    agg_id_data_min = {\n",
    "        \"set\": \"random_aggregated_min\",\n",
    "        \"total_snps_found\": id_data['total_snps_found'].min().astype(int),\n",
    "        \"total_snps_overlap\": id_data['total_snps_overlap'].min(),\n",
    "        \"total_loci_overlap\": id_data['total_loci_overlap'].min(),\n",
    "        \"total_coding_snps\": id_data['total_coding_snps'].min(),\n",
    "        \"average_p_value\": id_data['average_p_value'].min()\n",
    "    }\n",
    "\n",
    "    # Add the aggregated results to the main DataFrame\n",
    "    df = pd.concat([df, pd.DataFrame([agg_id_data_mean])], ignore_index=True)\n",
    "    df = pd.concat([df, pd.DataFrame([agg_id_data_median])], ignore_index=True)\n",
    "    df = pd.concat([df, pd.DataFrame([agg_id_data_max])], ignore_index=True)\n",
    "    df = pd.concat([df, pd.DataFrame([agg_id_data_min])], ignore_index=True)\n",
    "\n",
    "    return df\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result for window size = 1Mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hf/9rstklcn237dv4bv1x1d6x740000gn/T/ipykernel_20897/3988943723.py:18: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame([reference_dict])], ignore_index=True)\n",
      "/var/folders/hf/9rstklcn237dv4bv1x1d6x740000gn/T/ipykernel_20897/3988943723.py:36: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  id_data = pd.concat([id_data, pd.DataFrame([id_data_dict])], ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>set</th>\n",
       "      <th>total_snps_found</th>\n",
       "      <th>total_snps_overlap</th>\n",
       "      <th>total_loci_overlap</th>\n",
       "      <th>total_coding_snps</th>\n",
       "      <th>average_p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reference</td>\n",
       "      <td>45.0</td>\n",
       "      <td>6.0000</td>\n",
       "      <td>26.00</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>3.616732e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random_aggregated_mean</td>\n",
       "      <td>42.0</td>\n",
       "      <td>6.9375</td>\n",
       "      <td>27.25</td>\n",
       "      <td>4.5625</td>\n",
       "      <td>3.082382e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>random_aggregated_median</td>\n",
       "      <td>42.0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>27.00</td>\n",
       "      <td>4.5000</td>\n",
       "      <td>3.076975e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>random_aggregated_max</td>\n",
       "      <td>45.0</td>\n",
       "      <td>8.0000</td>\n",
       "      <td>29.00</td>\n",
       "      <td>6.0000</td>\n",
       "      <td>3.627492e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>random_aggregated_min</td>\n",
       "      <td>39.0</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>25.00</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>2.711803e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        set  total_snps_found  total_snps_overlap  \\\n",
       "0                 reference              45.0              6.0000   \n",
       "1    random_aggregated_mean              42.0              6.9375   \n",
       "2  random_aggregated_median              42.0              7.0000   \n",
       "3     random_aggregated_max              45.0              8.0000   \n",
       "4     random_aggregated_min              39.0              5.0000   \n",
       "\n",
       "   total_loci_overlap  total_coding_snps  average_p_value  \n",
       "0               26.00             5.0000     3.616732e-07  \n",
       "1               27.25             4.5625     3.082382e-07  \n",
       "2               27.00             4.5000     3.076975e-07  \n",
       "3               29.00             6.0000     3.627492e-07  \n",
       "4               25.00             3.0000     2.711803e-07  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = create_window_size_results(1000000)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total possible snps / overlap loci was 29. The performance of the brain tracks is worse than the random aggregated result.   In addition, we see that the number of matching snps in the random sets, on average is better than the reference set. We also see a lower number of snps found in the random tracks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result for window size = 750000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hf/9rstklcn237dv4bv1x1d6x740000gn/T/ipykernel_20897/3988943723.py:18: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame([reference_dict])], ignore_index=True)\n",
      "/var/folders/hf/9rstklcn237dv4bv1x1d6x740000gn/T/ipykernel_20897/3988943723.py:36: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  id_data = pd.concat([id_data, pd.DataFrame([id_data_dict])], ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>set</th>\n",
       "      <th>total_snps_found</th>\n",
       "      <th>total_snps_overlap</th>\n",
       "      <th>total_loci_overlap</th>\n",
       "      <th>total_coding_snps</th>\n",
       "      <th>average_p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reference</td>\n",
       "      <td>48.0000</td>\n",
       "      <td>6.0000</td>\n",
       "      <td>28.00</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>3.616732e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random_aggregated_mean</td>\n",
       "      <td>44.8125</td>\n",
       "      <td>6.8125</td>\n",
       "      <td>29.25</td>\n",
       "      <td>4.5625</td>\n",
       "      <td>3.082382e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>random_aggregated_median</td>\n",
       "      <td>45.0000</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>29.00</td>\n",
       "      <td>4.5000</td>\n",
       "      <td>3.076975e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>random_aggregated_max</td>\n",
       "      <td>48.0000</td>\n",
       "      <td>8.0000</td>\n",
       "      <td>31.00</td>\n",
       "      <td>6.0000</td>\n",
       "      <td>3.627492e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>random_aggregated_min</td>\n",
       "      <td>41.0000</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>27.00</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>2.711803e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        set  total_snps_found  total_snps_overlap  \\\n",
       "0                 reference           48.0000              6.0000   \n",
       "1    random_aggregated_mean           44.8125              6.8125   \n",
       "2  random_aggregated_median           45.0000              7.0000   \n",
       "3     random_aggregated_max           48.0000              8.0000   \n",
       "4     random_aggregated_min           41.0000              5.0000   \n",
       "\n",
       "   total_loci_overlap  total_coding_snps  average_p_value  \n",
       "0               28.00             5.0000     3.616732e-07  \n",
       "1               29.25             4.5625     3.082382e-07  \n",
       "2               29.00             4.5000     3.076975e-07  \n",
       "3               31.00             6.0000     3.627492e-07  \n",
       "4               27.00             3.0000     2.711803e-07  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = create_window_size_results(750000)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The reference value here is 31 and we have the brain tracks recovering 28 snps and the random sets recovering 29.25. The number of matching snps is higher on average in the random set, which is again suprising. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result for window size = 500000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hf/9rstklcn237dv4bv1x1d6x740000gn/T/ipykernel_20897/3988943723.py:18: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame([reference_dict])], ignore_index=True)\n",
      "/var/folders/hf/9rstklcn237dv4bv1x1d6x740000gn/T/ipykernel_20897/3988943723.py:36: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  id_data = pd.concat([id_data, pd.DataFrame([id_data_dict])], ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>set</th>\n",
       "      <th>total_snps_found</th>\n",
       "      <th>total_snps_overlap</th>\n",
       "      <th>total_loci_overlap</th>\n",
       "      <th>total_coding_snps</th>\n",
       "      <th>average_p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reference</td>\n",
       "      <td>54.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>34.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>3.616732e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random_aggregated_mean</td>\n",
       "      <td>48.5</td>\n",
       "      <td>7.25</td>\n",
       "      <td>35.25</td>\n",
       "      <td>6.25</td>\n",
       "      <td>3.082382e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>random_aggregated_median</td>\n",
       "      <td>48.5</td>\n",
       "      <td>7.00</td>\n",
       "      <td>35.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>3.076975e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>random_aggregated_max</td>\n",
       "      <td>51.0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>37.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>3.627492e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>random_aggregated_min</td>\n",
       "      <td>45.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>33.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.711803e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        set  total_snps_found  total_snps_overlap  \\\n",
       "0                 reference              54.0                6.00   \n",
       "1    random_aggregated_mean              48.5                7.25   \n",
       "2  random_aggregated_median              48.5                7.00   \n",
       "3     random_aggregated_max              51.0                9.00   \n",
       "4     random_aggregated_min              45.0                5.00   \n",
       "\n",
       "   total_loci_overlap  total_coding_snps  average_p_value  \n",
       "0               34.00               7.00     3.616732e-07  \n",
       "1               35.25               6.25     3.082382e-07  \n",
       "2               35.00               7.00     3.076975e-07  \n",
       "3               37.00               8.00     3.627492e-07  \n",
       "4               33.00               3.00     2.711803e-07  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = create_window_size_results(500000)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar results to above, the reference value is n = 37 with 1 coding snp. \n",
    "### Result for window size = 375000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hf/9rstklcn237dv4bv1x1d6x740000gn/T/ipykernel_20897/3988943723.py:18: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame([reference_dict])], ignore_index=True)\n",
      "/var/folders/hf/9rstklcn237dv4bv1x1d6x740000gn/T/ipykernel_20897/3988943723.py:36: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  id_data = pd.concat([id_data, pd.DataFrame([id_data_dict])], ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>set</th>\n",
       "      <th>total_snps_found</th>\n",
       "      <th>total_snps_overlap</th>\n",
       "      <th>total_loci_overlap</th>\n",
       "      <th>total_coding_snps</th>\n",
       "      <th>average_p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reference</td>\n",
       "      <td>57.0000</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>34.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>3.616732e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random_aggregated_mean</td>\n",
       "      <td>52.4375</td>\n",
       "      <td>8.1875</td>\n",
       "      <td>35.25</td>\n",
       "      <td>6.25</td>\n",
       "      <td>3.082382e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>random_aggregated_median</td>\n",
       "      <td>52.0000</td>\n",
       "      <td>8.0000</td>\n",
       "      <td>35.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>3.076975e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>random_aggregated_max</td>\n",
       "      <td>55.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>37.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>3.627492e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>random_aggregated_min</td>\n",
       "      <td>47.0000</td>\n",
       "      <td>6.0000</td>\n",
       "      <td>33.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.711803e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        set  total_snps_found  total_snps_overlap  \\\n",
       "0                 reference           57.0000              7.0000   \n",
       "1    random_aggregated_mean           52.4375              8.1875   \n",
       "2  random_aggregated_median           52.0000              8.0000   \n",
       "3     random_aggregated_max           55.0000             10.0000   \n",
       "4     random_aggregated_min           47.0000              6.0000   \n",
       "\n",
       "   total_loci_overlap  total_coding_snps  average_p_value  \n",
       "0               34.00               7.00     3.616732e-07  \n",
       "1               35.25               6.25     3.082382e-07  \n",
       "2               35.00               7.00     3.076975e-07  \n",
       "3               37.00               8.00     3.627492e-07  \n",
       "4               33.00               3.00     2.711803e-07  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = create_window_size_results(375000)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar results to above, the reference value is n = 37 with 0 coding snps. \n",
    "### Result for window size = 250000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hf/9rstklcn237dv4bv1x1d6x740000gn/T/ipykernel_20897/3988943723.py:18: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame([reference_dict])], ignore_index=True)\n",
      "/var/folders/hf/9rstklcn237dv4bv1x1d6x740000gn/T/ipykernel_20897/3988943723.py:36: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  id_data = pd.concat([id_data, pd.DataFrame([id_data_dict])], ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>set</th>\n",
       "      <th>total_snps_found</th>\n",
       "      <th>total_snps_overlap</th>\n",
       "      <th>total_loci_overlap</th>\n",
       "      <th>total_coding_snps</th>\n",
       "      <th>average_p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reference</td>\n",
       "      <td>61.0000</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>41.00</td>\n",
       "      <td>8.000</td>\n",
       "      <td>3.616732e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random_aggregated_mean</td>\n",
       "      <td>55.6875</td>\n",
       "      <td>8.1875</td>\n",
       "      <td>42.25</td>\n",
       "      <td>7.375</td>\n",
       "      <td>3.082382e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>random_aggregated_median</td>\n",
       "      <td>56.0000</td>\n",
       "      <td>8.0000</td>\n",
       "      <td>42.00</td>\n",
       "      <td>8.000</td>\n",
       "      <td>3.076975e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>random_aggregated_max</td>\n",
       "      <td>59.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>44.00</td>\n",
       "      <td>10.000</td>\n",
       "      <td>3.627492e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>random_aggregated_min</td>\n",
       "      <td>49.0000</td>\n",
       "      <td>6.0000</td>\n",
       "      <td>40.00</td>\n",
       "      <td>4.000</td>\n",
       "      <td>2.711803e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        set  total_snps_found  total_snps_overlap  \\\n",
       "0                 reference           61.0000              7.0000   \n",
       "1    random_aggregated_mean           55.6875              8.1875   \n",
       "2  random_aggregated_median           56.0000              8.0000   \n",
       "3     random_aggregated_max           59.0000             10.0000   \n",
       "4     random_aggregated_min           49.0000              6.0000   \n",
       "\n",
       "   total_loci_overlap  total_coding_snps  average_p_value  \n",
       "0               41.00              8.000     3.616732e-07  \n",
       "1               42.25              7.375     3.082382e-07  \n",
       "2               42.00              8.000     3.076975e-07  \n",
       "3               44.00             10.000     3.627492e-07  \n",
       "4               40.00              4.000     2.711803e-07  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = create_window_size_results(250000)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar results to above, the reference value is n = 44. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial impressions: This analysis was not what I expected. I will perform some additional analyses, however it seems that we may want to reconsider if the tracks should be highly tissue dependent. At 1.0 SD, we see a minor advantage for the brain tracks, so it may be that using these is still beneficial. It may also be that this method is highly effective at eliminating non-causal SNPs, regardless of the track choice."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
